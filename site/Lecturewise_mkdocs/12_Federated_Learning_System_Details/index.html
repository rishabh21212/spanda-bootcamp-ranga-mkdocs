
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../11_Federated_Learning/">
      
      
        <link rel="next" href="../13_Federated_Learning_Implementation_-_Server_Side/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.7">
    
    
      
        <title>12 Federated Learning System Details - Spanda DL Bootcamp</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.f2e4d321.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Spanda DL Bootcamp" class="md-header__button md-logo" aria-label="Spanda DL Bootcamp" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Spanda DL Bootcamp
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              12 Federated Learning System Details
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_2">
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  The Complete Generative AI Bootcamp

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../01_Course_Vision_and_Running_a_Local_LLM/" class="md-tabs__link">
          
  
  Lecturewise mkdocs

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Spanda DL Bootcamp" class="md-nav__button md-logo" aria-label="Spanda DL Bootcamp" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Spanda DL Bootcamp
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Complete Generative AI Bootcamp
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Lecturewise mkdocs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Lecturewise mkdocs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01_Course_Vision_and_Running_a_Local_LLM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    01 Course Vision and Running a Local LLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../02_Software_Engineering_for_AI/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    02 Software Engineering for AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03_Ops_-_DevOps%2C_MLOps%2C_AIOps/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    03 Ops   DevOps, MLOps, AIOps
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04_Data_Collection%2C_Data_Labeling%2C_Data_Management%2C_Analytics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    04 Data Collection, Data Labeling, Data Management, Analytics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05_Testing_and_Deployment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    05 Testing and Deployment
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06.5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    06.5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06_LLM_Serving_and_Reinforcement_Learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    06 LLM Serving and Reinforcement Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../07_Distributed_Systems_Patterns/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    07 Distributed Systems Patterns
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../08_Workflow_Patterns/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    08 Workflow Patterns
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../09_Scheduling_%26amp%3B_Metadata_Patterns/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    09 Scheduling &amp; Metadata Patterns
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10_Data_Lakes_%26amp%3B_Intro_to_Federated_Learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    10 Data Lakes &amp; Intro to Federated Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11_Federated_Learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    11 Federated Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    12 Federated Learning System Details
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../13_Federated_Learning_Implementation_-_Server_Side/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    13 Federated Learning Implementation   Server Side
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../14_Federated_Learning_Implementation_-_Client_Side/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    14 Federated Learning Implementation   Client Side
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15_Federated_Learning_Running_the_System_%26amp%3B_Analyzing_Results/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    15 Federated Learning Running the System &amp; Analyzing Results
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16_Introducing_Existing_Federated_Learning_Frameworks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    16 Introducing Existing Federated Learning Frameworks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17_Federated_Learning_Use_Cases_and_Case_Studies/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    17 Federated Learning Use Cases and Case Studies
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18_Federated_Learning_Future_Directions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    18 Federated Learning Future Directions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19_LLMs_and_NLP_Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLM's & NLP Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20_Retrieval_Augmented_Generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Retrieval Augmented Generation (RAG)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../21_RAG_Pipeline_Implementation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RAG Pipeline Implementation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../22_From_Simple_to_Advanced_RAG/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    From Simple to Advanced RAG
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../23_RAG_Observability/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Observability Tools for RAG
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>12 Federated Learning System Details</h1>

<p><strong>Federated Learning Systems</strong></p>
<ul>
<li>
<p>This section will provide an overview of the architecture, procedure
    flow, sequence of messages, and basics of model aggregation of
    the <strong>federated learning</strong> (<strong>FL</strong>) system.</p>
</li>
<li>
<p>As discussed earlier, the basics of the FL framework is quite easy
    to understand. However, the real implementation of the FL framework
    needs to come with a good understanding of both AI and distributed
    systems.</p>
</li>
<li>
<p>The content of this section is based on the most standard foundation
    of FL systems, which is used in hands-on exercises later.</p>
</li>
<li>
<p>First, we will introduce the building blocks of FL systems, such as
    an aggregator with an FL server, an agent with an FL client, a
    database server, and communication between these components.</p>
</li>
<li>
<p>The architecture introduced here is designed in a decoupled way so
    that further enhancement to the system will be relatively easier
    than with an FL system that contains everything on one machine.</p>
</li>
<li>
<p>Then, an explanation of the flow of the operation of FL from
    initialization to aggregation will follow.</p>
</li>
<li>
<p>Finally, we will examine the way an FL system is scaled with a
    horizontal design of decentralized FL setups.</p>
</li>
</ul>
<p>This section covers the following topics:</p>
<ul>
<li>
<p>FL system architecture</p>
</li>
<li>
<p>Understanding the FL system flow -- from initialization to
    continuous operation</p>
</li>
<li>
<p>Basics of model aggregation</p>
</li>
<li>
<p>Furthering scalability with horizontal design</p>
</li>
</ul>
<p>The System Architecture</p>
<ul>
<li>
<p>FL systems are distributed systems that are comprised of servers and
    distributed clients.</p>
</li>
<li>
<p>Here, we will define a representative architecture of an FL system
    with the following components: an aggregator with an FL server, an
    agent with an FL client, and a database:</p>
</li>
</ul>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>&lt;!-- --&gt;
</code></pre></div>
-   <strong>Cluster aggregator</strong> (or <strong>aggregator</strong>): A system with an FL
    server that collects and aggregates <strong>machine learning</strong> (<strong>ML</strong>)
    models that are trained at multiple distributed agents (defined
    shortly) and creates global ML models that are sent back to the
    agents. This system serves as a <em>cluster aggregator</em>, or more
    simply, an <em>aggregator</em> of FL systems.</p>
<ul>
<li>
<p><strong>Distributed agent</strong> (or <strong>agent</strong>): A distributed
    learning environment with an FL client such as a local edge device,
    mobile application, tablet, or any distributed cloud environment
    where ML models are trained in a distributed manner and sent to an
    aggregator. The agent can be connected to an FL server of the
    aggregator through the FL client-side communications module. The FL
    client-side codes contain a collection of libraries that can be
    integrated into the local ML application, which is designed and
    implemented by individual ML engineers and data scientists.</p>
</li>
<li>
<p><strong>Database server</strong> (or <strong>database</strong>): A database and its server to
    store the data related to the aggregators, agents, and global and
    local ML models and their performance metrics. The database server
    handles the incoming queries from the aggregators and sends the
    necessary data back to the aggregators. Agents do not have to be
    connected to the database server directly for the simplicity of the
    FL system design.</p>
</li>
</ul>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>&lt;!-- --&gt;
</code></pre></div>
-   <em>Figure 3.1</em> shows the typical overall architecture consisting of a
    single cluster aggregator and a database server, as well as multiple
    distributed agents:</p>
<p><img alt="Figure 3.1 -- Overall architecture of an FL system
" src="../images/media/image81.jpg" />{width="6.268055555555556in"
height="4.414583333333334in"}</p>
<p>Figure 3.1 -- Overall architecture of an FL system</p>
<ul>
<li>
<p>One advantage of the FL system's architecture is that users do not
    have to send private raw data to the server, especially that owned
    by a third party. Instead, they only have to send locally trained
    models to the aggregator.</p>
</li>
<li>
<p>The locally trained models can be in a variety of formats such as
    the weights of the entire ML models, the changes of weights
    (gradients), or even a subset of them.</p>
</li>
<li>
<p>Another advantage includes reducing the communication load because
    the users only have to exchange models that are usually much lighter
    than raw data.</p>
</li>
</ul>
<p>The Cluster aggregators</p>
<ul>
<li>
<p>A cluster aggregator consists of an FL server module, FL state
    manager module, and model aggregation module, as in <em>Figure 3.1</em>.</p>
</li>
<li>
<p>We just call a cluster aggregator with an FL server an aggregator.</p>
</li>
<li>
<p>While these modules are the foundation of the aggregator, advanced
    modules can be added to ensure further security and flexibility of
    the aggregation of ML models.</p>
</li>
<li>
<p>Some of the advanced modules are not implemented in
    the simple-fl GitHub repository provided with exercises because the
    main purpose of this effort is to understand the basic structure and
    system flow of the FL system.</p>
</li>
<li>
<p>In the aggregator system, the following modules related to the FL
    server, the state manager of FL, and model aggregation are the keys
    to implementing the aggregator-side functionalities.</p>
</li>
</ul>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>&lt;!-- --&gt;
</code></pre></div>
-   <strong>FL server module</strong>: There are three primary functionalities for
    the FL server module, which include the communication handler,
    system configuration handler, and model synthesis routine:</p>
<div class="highlight"><pre><span></span><code>-   **Communication handler**: Serves as a module of the aggregator
    that supports *communications with agents and the database*.
    Usually, this module accepts polling messages from agents and
    sends responses back to them. The types of messages they receive
    include the registration of agents themselves with secure
    credentials and authentication mechanisms, the initialization of
    the ML model that serves as an *initial model* for the future
    aggregation process, confirmation about whether or not agents
    participate in a round, and local ML models that are retrained
    at distributed agents such as mobile devices and local edge
    machines. The communication handler can also query the database
    server in order to access the system data and ML models in the
    database, as well as push and store this data and those models
    once the aggregator receives or creates new models. This module
    can utilize HTTP, WebSocket, or any other communication
    framework for its implementation.

-   **System configuration handler**: Deals with the *registration
    of agents* and tracking the connected agents and their statuses.
    The aggregator needs to be aware of the connections and
    registration statuses of the agents. If the agents are
    registered with an established authentication mechanism, they
    will accept the messages and process them accordingly.
    Otherwise, this module will go through the authentication
    process, such as validating the token sent from the agent, so
    that next time this agent is connected to the FL server, the
    system will recognize the agent properly.

-   **Model synthesis routine**: Supports checking the collection
    status of the local ML models and aggregating them once the
    collection criteria are satisfied. Collection criteria include
    the number of local models collected by the connected agents.
    For example, aggregation can happen when 80% of the connected
    agents send the trained local models to the aggregator. One of
    the design patterns to do so is to periodically check the number
    of ML models uploaded by the agents, which keep running while
    the FL server is up and running. The model synthesis routine
    will access the database or local buffer periodically to check
    the status of the local model collection and aggregate those
    models, to produce the global model that will be stored in the
    database server and sent back to the agents.
</code></pre></div>
<ul>
<li>
<p><strong>FL state manager</strong>: A state manager keeps track of the state
    information of an aggregator and connected agents. It stores
    volatile information for an aggregator, such as local and global
    models delivered by agents, cluster models pulled from the database,
    FL round information, or agents connected to the aggregator. The
    buffered local models are used by the model aggregation module to
    generate a global model that is sent back to each active agent
    connected to the aggregator.</p>
</li>
<li>
<p><strong>Model aggregation module</strong>: The model aggregation module is a
    collection of the model aggregation algorithms introduced in
    the <em>Basics of model aggregation</em> section here and in <em>Model
    Aggregation</em>, in further depth. The most typical aggregation
    algorithm is <em>federated averaging</em>, which averages the weights of
    the collected ML models, considering the number of samples that each
    model has used for its local training.</p>
</li>
</ul>
<p>Distributed agents</p>
<ul>
<li>A distributed agent consists of an FL client module that includes
    the communication handler and client libraries as well as local ML
    applications connected to the FL system through the FL client
    libraries:</li>
</ul>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>&lt;!-- --&gt;
</code></pre></div>
-   <strong>FL client module</strong>: There are primarily four key functionalities
    for the FL client module, which include a communication handler,
    agent participation handler, model exchange routine, and client
    libraries:</p>
<div class="highlight"><pre><span></span><code>-   **Communication handler**: Serves as a channel to communicate
    with the aggregator that is assigned to the agent. The message
    sent to the aggregator includes the registration payload of the
    agent itself and an initial model that will be the basis of
    aggregated models. The message also contains locally trained
    models together with the performance data of those models. This
    module supports both *push* and *polling* mechanisms and can
    utilize HTTP or WebSocket frameworks for its implementation.

-   **FL participation handler**: Deals with the agent participation
    in the FL process and cycle by sending an aggregator a message
    including the agent information itself to be registered in the
    FL platform and initialize the FL process if needed. The
    response message will set the agent up for the continuous and
    ongoing FL process and often includes the most updated global
    model for the agent to utilize and train locally.

-   **Model exchange routine**: Supports a synchronizing
    functionality that constantly checks whether a new global model
    is available or not. If the new global model is available, this
    module downloads the global model from the aggregator and the
    global model replaces the local model if needed. This module
    also checks the client state and sends the retrained model if
    the local training process is done.

-   **Client libraries**: Include administrative libraries and
    general FL client libraries:

    -   The administrative libraries are used when registering the
        initial model that will be used by other agents. Any
        configuration changes for FL systems can be also requested
        by administrative agents that have higher control
        capabilities.

    -   General FL client libraries provide basic functionalities
        such as starting FL client core threads, sending local
        models to an aggregator, saving models in some specific
        location on the local machine, manipulating the client
        state, and downloading the global models. This book mainly
        talks about this general type of library.
</code></pre></div>
<ul>
<li><strong>Local ML engine and data pipelines</strong>: These parts are designed by
    individual ML engineers and scientists and can be independent of the
    FL client functionalities. This module has an ML model itself that
    can be put into play immediately by the user for potentially more
    accurate inference, a training and testing environment that can be
    plugged into the FL client libraries, and for the implementation of
    data pipelines. While the aforementioned module and libraries can be
    generalized and provided as <strong>application programming
    interfaces</strong> (<strong>APIs</strong>) or libraries for any ML applications, this
    module is unique depending on the requirements of AI applications to
    be developed.</li>
</ul>
<p>The Database Components</p>
<ul>
<li>
<p>A database server consists of a database query handler and a
    database, as storage.</p>
</li>
<li>
<p>The database server can reside on the server side, such as on the
    cloud, and is tied closely to aggregators, while the recommended
    design is to separate this database server from aggregator servers
    to decouple the functionalities to enhance the system's simplicity
    and resilience.</p>
</li>
<li>
<p>The functionality of the database query handler and sample database
    tables are as follows:</p>
</li>
</ul>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>&lt;!-- --&gt;
</code></pre></div>
-   <strong>Database query handler</strong>: Accepts the incoming requests from an
    aggregator and sends the requested data and ML models back to the
    aggregator.</p>
<ul>
<li>
<p><strong>Database</strong>: Stores all the related information to FL processes. We
    list some potential entries for the database here:</p>
<ul>
<li>
<p><strong>Aggregator information</strong>: This aggregator-related information
    includes the ID of the aggregator itself, the IP address and
    various port numbers, system registered and updated times, and
    system status. In addition, this entry can include model
    aggregation-related information, such as the round of FL and its
    information and aggregation criteria.</p>
</li>
<li>
<p><strong>Agent information</strong>: This agent-related information includes
    the ID of the agent itself, the IP address and various port
    numbers, system registered and updated times, and system status.
    This entry can also contain the opt-in/out status that is used
    for synchronous FL (explained in the <em>Synchronous and
    asynchronous FL</em> section Here) and a flag to record whether the
    agent has been a bad actor in the past (for example, involved in
    poisoning attacks, or very slow at returning results).</p>
</li>
<li>
<p><strong>Base model information</strong>: Base model information is used for
    the registration of initial ML models whose architecture and
    information are used for the entire process of FL rounds.</p>
</li>
<li>
<p><strong>Local models</strong>: The information of local models includes the
    model ID that is unique to individual ML models, generated time
    of the model, agent ID that uploaded the model, aggregator ID
    that received the model from the agent, and so on. Usually, the
    model ID is uniquely mapped to the location of the actual ML
    model file that can be stored in the database server or in some
    cloud storage services such as S3 buckets of Amazon Web
    Services, and so on.</p>
</li>
<li>
<p><strong>Cluster global models</strong>: The information of the cluster global
    models is similar to what local models could record in the
    database including the model ID, aggregator ID, generated time
    of the model, and so on. Once the aggregated model is created by
    an aggregator, the database server will accept the global models
    and store them in the database server or any cloud storage
    services. Any global model can be requested by an aggregator.</p>
</li>
<li>
<p><strong>Performance data</strong>: The performance of the local and global
    models can be tracked, as metadata attached to those models.
    This performance data will be used to ensure that the aggregated
    model performs well enough before it is actually deployed to the
    user ML application.</p>
</li>
</ul>
</li>
</ul>
<p>Note</p>
<ul>
<li>
<p>In the code sample of the simple-fl repository, only the database
    tables related to the local models and cluster models are covered to
    simplify the explanation of the entire FL process.</p>
</li>
<li>
<p>Now that the basic architecture of the FL system has been
    introduced, next, we will talk about how to enhance the FL system's
    architecture if the computation resources are limited on the
    agent-side devices.</p>
</li>
</ul>
<p>Low Computational Capacity Agent Devices and Intermediate servers</p>
<ul>
<li>
<p>Sometimes, the computational capability of local user devices is
    limited -- ML training may be difficult in those devices, but
    inference or predictions can be made possible by just downloading
    the global model. In these cases, an FL platform may be able to set
    up an additional intermediate server layer, such as with
    smartphones, tablets, or edge servers.</p>
</li>
<li>
<p>For example, in a healthcare AI application, users manage their
    health information on their smart watches, which can be transferred
    to their smart tablets or synched with laptops. In those devices, it
    is easy to retrain ML models and integrate the distributed agent
    functionalities.</p>
</li>
<li>
<p>Therefore, the system architecture needs to be modified or
    redesigned depending on the applications into which the FL system is
    integrated, and the concept of intermediate servers can be applied
    using distributed agents to realize FL processes.</p>
</li>
<li>
<p>We do not have to modify the interactions and communication
    mechanisms between the aggregators and the intermediate servers.
    Just by implementing APIs between the user devices and the
    intermediate servers, FL will be possible in most use cases.</p>
</li>
</ul>
<p><em>Figure 3.2</em> illustrates the interaction between the aggregators,
intermediate servers, and user devices:</p>
<p><img alt="Figure 3.2 -- An FL system with intermediate servers
" src="../images/media/image79.jpg" />{width="6.268055555555556in"
height="3.623611111111111in"}</p>
<p>Figure 3.2 -- An FL system with intermediate servers</p>
<ul>
<li>Now that we have learned about the basic architecture and components
    of an FL system, let us look into how an FL system operates in the
    following section.</li>
</ul>
<p>FL System Process -- from initialization to continuous operation</p>
<ul>
<li>
<p>Each distributed agent belongs to an aggregator that is managed by
    an FL server, where ML model aggregation is conducted to synthesize
    a global model that is going to be sent back to the agents.</p>
</li>
<li>
<p>An agent uses its local data to train an ML model and then uploads
    the trained model to the corresponding aggregator. The concept
    sounds straightforward, so we will look into a bit more detail to
    realize the entire flow of those processes.</p>
</li>
<li>
<p>We also define a <strong>cluster global model</strong>, which we simply call
    a <strong>cluster model</strong> or <strong>global model</strong>, which is an aggregated ML
    model of local models collected from distributed agents.</p>
</li>
</ul>
<p>Note</p>
<ul>
<li>
<p>In the next two sections, we will guide you on how to implement the
    procedure and sequence of messages discussed Here.</p>
</li>
<li>
<p>However, some of the system operation perspectives, such as an
    aggregator or agent system registration in the database, are not
    introduced in the code sample of the simple-fl repository in order
    to simplify the explanation of the entire FL process.</p>
</li>
</ul>
<p>Database, Aggregator, and Agent initialization</p>
<ul>
<li>
<p>The sequence of the initialization processes is quite simple. The
    initialization and registration processes need to happen in the
    order of database, aggregator, and agents.</p>
</li>
<li>
<p>The overall registration sequence of an aggregator and an agent with
    a database is depicted in <em>Figure 3.3</em> as follows:</p>
</li>
</ul>
<p><img alt="Figure 3.3 -- The process of aggregator and agent registration in the
database server
" src="../images/media/image14.jpg" />{width="6.268055555555556in"
height="6.290972222222222in"}</p>
<p>Figure 3.3 -- The process of aggregator and agent registration in the
database server</p>
<p>Here is the initialization and registration procedure of each component
in the FL system:</p>
<ul>
<li>
<p><strong>Database server initialization</strong>: The first step of the operation
    of an FL system is to initiate the database server. There are some
    simple frameworks that are provided by multiple organizations that
    do not include databases or database servers. However, in order to
    maintain the process of federating the ML models, it is recommended
    that you use a database, even a lightweight one such as an SQLite
    database.</p>
</li>
<li>
<p><strong>Aggregator initialization and registration</strong>: An aggregator should
    be set up and running before any agents start running and uploading
    the ML models. When the aggregator starts running and first gets
    connected to the database server, the registration process happens
    automatically by also checking whether the aggregator is safe to be
    connected. If it fails to go through the registration process, it
    receives the registration failure message sent back from the
    database. Also, in case the aggregator is trying to connect to
    the database again after losing the connection to the database, the
    database server always checks whether the aggregator has already
    been registered or not. If this is the case, the response from the
    database server includes the system information of the registered
    aggregator so that the aggregator can start from the point where it
    left off. The aggregator may need to publish an IP address and port
    number for agents to be connected if it uses HTTP or WebSocket.</p>
</li>
<li>
<p><strong>Agent initialization and registration</strong>: Usually, if an agent
    knows the aggregator that the agent wants to connect to, the
    registration is similar to how an aggregator connects to a database
    server. The connection process should be straightforward enough to
    just send a participation message to that aggregator using an IP
    address, the port number of the aggregator (if we are using some
    frameworks such as HTTP or WebSocket), and an authentication token.
    In case the agent is trying to connect to the aggregator again after
    losing the connection to the aggregator, the database server always
    checks whether the agent already has been registered or not. If the
    agent is already registered, the response from the database server
    includes the system information of the registered agent so that the
    agent can start from the point where it was disconnected from the
    aggregator.</p>
</li>
</ul>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>&lt;!-- --&gt;
</code></pre></div>
-   In particular, when it receives the participation message from the
    agent, the aggregator goes through the following procedure, as
    in <em>Figure 3.4</em>.</p>
<ul>
<li>
<p>The key process after receiving the participation request is (i)
    checking whether the agent is trusted or not, or whether the agent
    is already registered or not, and (ii) checking whether the initial
    global model is already registered or not. If (i) is met, the
    registration process keeps going. If the (initial) global model is
    already registered, the agent will be able to receive the global
    model and start using that global model for the local training
    process on the agent side.</p>
</li>
<li>
<p>The agent participation and registration process at an aggregator
    side is depicted in <em>Figure 3.4</em>:</p>
</li>
</ul>
<p><img alt="Figure 3.4 -- The registration process of an agent by an aggregator
" src="../images/media/image8.jpg" />{width="6.268055555555556in"
height="6.81875in"}</p>
<p>Figure 3.4 -- The registration process of an agent by an aggregator</p>
<ul>
<li>Now that we understand the initialization and registration process
    of the FL system components, let us move on to the basic
    configuration of the ongoing FL process, which is about uploading
    the initial ML model.</li>
</ul>
<p>Initial model upload process by initial agent</p>
<ul>
<li>
<p>The next step in running an FL process is to register the initial ML
    model whose architecture will be used in the entire and continuous
    process of FL by all the aggregators and agents.</p>
</li>
<li>
<p>The initial model can be distributed by the company that owns the ML
    application and FL servers.</p>
</li>
<li>
<p>They'll likely provide the initial base model as part of the
    aggregator configuration.</p>
</li>
<li>
<p>We call the initial ML model used as a reference for model
    aggregation a <strong>base model</strong>.</p>
</li>
<li>
<p>We also call the agent that uploads the initial base model
    an <em>initial agent</em>. The base model info could include the ML model
    itself as well as the time it was generated and the initial
    performance data.</p>
</li>
<li>
<p>That being said, the process of initializing the base model can be
    seen in <em>Figure 3.5</em>:</p>
</li>
</ul>
<p><img alt="Figure 3.5 -- Base model upload process for the initial agent
" src="../images/media/image3.jpg" />{width="6.268055555555556in"
height="5.909722222222222in"}</p>
<p>Figure 3.5 -- Base model upload process for the initial agent</p>
<ul>
<li>Now, the FL process is ready to be conducted. Next, we will learn
    about the FL cycle, which is a very core part of the FL process.</li>
</ul>
<p>Overall FL System Process Sequence</p>
<ul>
<li>
<p>In this section, we will only give an example with a single agent
    and aggregator, but in real cases and operations, the agent
    environments are various and dispersed into distributed devices.</p>
</li>
<li>
<p>The following is the list of the processes for how the local models
    are uploaded, aggregated, stored, and sent back to agents as a
    global model:</p>
</li>
<li>
<p>The agents other than the initial agent will request the global
    model, which is an updated aggregated ML model, in order to deploy
    it to their own applications.</p>
</li>
<li>
<p>Once the agent gets the updated model from the aggregator and
    deploys it, the agent retrains the ML model locally with new data
    that is obtained afterward to reflect the freshness and timeliness
    of the data. An agent can also participate in multiple rounds with
    different data to absorb its local examples and tendencies. Again,
    this local data will not be shared with the aggregator and stays
    local to the distributed devices.</p>
</li>
<li>
<p>After retraining the local ML model (which, of course, has the same
    architecture as the global or base model of the FL), the agent calls
    an FL client API to send the model to the aggregator.</p>
</li>
<li>
<p>The aggregator receives the local ML model and pushes the model to
    the database. The aggregator keeps track of the number of collected
    local models and will keep accepting the local models as long as the
    federation round is open. The round can be closed with any defined
    criteria, such as the aggregator receiving enough ML models to be
    aggregated. When the criteria are met, the aggregator aggregates the
    local models and produces an updated global model that is ready to
    be sent back to the agent.</p>
</li>
<li>
<p>During that process, agents constantly poll the aggregator on
    whether the global model is ready or not, or in some cases, the
    aggregator may push the global model to the agents that are
    connected to the aggregator, depending on the communications system
    design and network constraints. Then, the updated model is sent back
    to the agent.</p>
</li>
<li>
<p>After receiving the updated global model, the agent deploys and
    retrains the global model locally whenever it is ready. The whole
    process described is repeated until the termination criteria are met
    for the FL to end. In some cases, there are no termination
    conditions to stop this FL cycle and retraining process so that the
    global model constantly keeps learning about the latest phenomena,
    current trends, or user-related tendencies. FL rounds can just be
    stopped manually in preparation for some evaluation before a
    rollout.</p>
</li>
</ul>
<p><em>Figure 3.6</em> shows the overall process of how FL is continuously
conducted between an agent, an aggregator, and a database typically:</p>
<p><img alt="Figure 3.6 -- Overview of the continuous FL cycle
" src="../images/media/image7.jpg" />{width="6.268055555555556in"
height="6.572222222222222in"}</p>
<p>Figure 3.6 -- Overview of the continuous FL cycle</p>
<ul>
<li>Now that we understand the overall procedure of the FL process, we
    will look into the different round management approaches in the FL
    process next: synchronous FL and asynchronous FL.</li>
</ul>
<p>Synchronous and asynchronous FL</p>
<ul>
<li>
<p>When the model aggregation happens at the aggregator, there are
    multiple criteria related to how many local models it needs to
    collect from which agents.</p>
</li>
<li>
<p>In this section, we will briefly talk about the differences between
    synchronous and asynchronous FL, which have been discussed in a lot
    of literature, such as
    https://iqua.ece.toronto.edu/papers/ningxinsu-iwqos22.pdf, so please
    refer to it to learn about these concepts further.</p>
</li>
</ul>
<p>Synchronous FL</p>
<ul>
<li>
<p>Synchronous FL requires the aggregator to select the agents that
    need to send the local models for each round in order to proceed
    with the model aggregation.</p>
<ul>
<li>
<p>This synchronous FL approach is simple to design and implement
    and suitable for FL applications that require a clear selection
    of agents.</p>
</li>
<li>
<p>However, if the number of agents becomes too large, the
    aggregator may have to wait for a long time to wrap up the
    current round, as the computational capability of the agents
    could vary and some of them may have problems uploading or fail
    to upload their local models.</p>
</li>
<li>
<p>Thus, some of the agents can become slow or totally
    dysfunctional when sending their models to the aggregator.</p>
</li>
<li>
<p>These slow agents are known as <em>stragglers</em> in distributed ML,
    which motivates us to use the asynchronous FL mode.</p>
</li>
</ul>
</li>
</ul>
<p>Asynchronous FL</p>
<ul>
<li>
<p>Asynchronous FL does not require the aggregator to select the agents
    that have to upload their local models. Instead, it opens the door
    for any trusted agents to upload the model anytime.</p>
</li>
<li>
<p>Furthermore, it is fine to wrap up the federation round whenever the
    aggregator wants to generate the global model, with or without
    criteria such as the minimum number of local models that needs to be
    collected, or some predefined interval or deadline for which the
    aggregator needs to wait to receive the local models from the agents
    until the aggregation for that round happens.</p>
</li>
<li>
<p>This asynchronous FL approach gives the FL system much more
    flexibility for model aggregation for each FL round, but the design
    may be more complicated than the simple synchronous aggregation
    framework.</p>
</li>
<li>
<p>When managing the FL rounds, you need to consider the practicalities
    of running rounds, such as scheduling and dealing with delayed
    responses, the minimum levels of participation required, the details
    of example stores, using the downloaded or trained models for
    improved inference in the applications on the edge devices, and
    dealing with bad or slow agents.</p>
</li>
<li>
<p>We will look into the FL process and procedure flow next, focusing
    on the aggregator side.</p>
</li>
</ul>
<p>FL cycle and process- The aggregator perspective</p>
<ul>
<li>An aggregator has two threads running to accept and cache the local
    models and aggregate the collected local ML models. In this section,
    we describe those procedures.</li>
</ul>
<p>Accepting and caching local ML models</p>
<ul>
<li>
<p>The aggregator side process of accepting and caching local ML models
    is depicted in <em>Figure 3.7</em> and explained as follows:</p>
</li>
<li>
<p>The aggregator will wait for a local ML model to be uploaded by an
    agent. This method sounds like asynchronous FL. However, if the
    aggregator has already decided which agents to accept models from,
    it just needs to exclude the model uploads sent by undesired agents.
    Some other system or module may have already told the undesired
    agents not to participate in the round as well.</p>
</li>
<li>
<p>Once an ML model is received, the aggregator checks whether the
    model is uploaded by the trusted agents or not. Also, if the agent
    that uploads the local model is not listed in the agents that the FL
    operator wants to accept, the aggregator will discard the model.
    Furthermore, an aggregator needs to have a mechanism to only filter
    the valid models -- otherwise, there is a risk of poisoning the
    global model and messing up the entire FL process.</p>
</li>
<li>
<p>If the uploaded local ML model is valid, the aggregator will push
    the model to the database. If the database resides on a different
    server, the aggregator will package the model and send it to the
    database server.</p>
</li>
<li>
<p>While the uploaded models are stored in the database, they should be
    buffered in the memory of the state manager of the aggregator in an
    appropriate format, such as NumPy arrays.</p>
</li>
<li>
<p>This procedure keeps running until the termination conditions are
    satisfied or the operator of the FL system opts to stop the
    process. <em>Figure 3.7</em> depicts the procedure of accepting and caching
    local ML models:</p>
</li>
</ul>
<p><img alt="Figure 3.7 -- Procedure for accepting and caching local ML models
" src="../images/media/image2.jpg" />{width="6.268055555555556in"
height="6.972916666666666in"}</p>
<p>Figure 3.7 -- Procedure for accepting and caching local ML models</p>
<ul>
<li>Once the local ML models are accepted and cached, the FL system
    moves on to the next procedure: aggregating the local models.</li>
</ul>
<p>Aggregating local ML models</p>
<ul>
<li>
<p>The aggregator-side procedure of aggregating local ML models
    depicted in <em>Figure 3.8</em> is as follows:</p>
</li>
<li>
<p>The aggregator constantly checks whether the aggregation criteria
    are satisfied. The typical aggregation criteria are as follows:</p>
<ul>
<li>
<p>The number of local models collected so far in this FL round.
    For example, if the number of agents is 10 nodes, after 8 nodes
    (meaning 80% nodes) report the locally trained models, the
    aggregator starts aggregating the models.</p>
</li>
<li>
<p>The combination of the number of collected models and the time
    that the FL round has spent. This can automate the aggregation
    process and prevent systems from getting stuck.</p>
</li>
</ul>
</li>
<li>
<p>Once the aggregation criteria are met, the aggregator starts a model
    aggregation process. Usually, federated averaging is a very typical
    but powerful aggregation method. Further explanation of the model
    aggregation methods is in the <em>Basics of model aggregation</em> section
    of This section and in <a href="https://subscription.packtpub.com/book/data/9781803247106/4/ch04lvl1sec23/B18369_07.xhtml#_idTextAnchor176"><em>section
    7</em></a>, <em>Model
    Aggregation</em>. The aggregated model is defined as a global model in
    this FL round.</p>
</li>
<li>
<p>In a case where time for the FL round has expired and not enough
    agents that participated in the round have uploaded a model, the
    round can be abandoned or forced to conduct aggregation for the
    local models collected so far.</p>
</li>
<li>
<p>Once the model aggregation is complete, the aggregator pushes the
    aggregated global model to the database. If the database resides on
    a different server, the aggregator will package the global model and
    send it to the database server.</p>
</li>
<li>
<p>Then, the aggregator sends the global model to all the agents, or
    when the agents poll to check whether the global model is ready, the
    aggregator will notify the agent that the global model is ready and
    put it in the response message to the agents.</p>
</li>
<li>
<p>After the whole process of model aggregation, the aggregator updates
    the number of the FL round by just incrementing it.</p>
</li>
<li>
<p><em>Figure 3.8</em> shows the aggregator's process from checking the
    aggregation criteria to synthesizing the global model when enough
    models are collected:</p>
</li>
</ul>
<p><img alt="Figure 3.8 -- Model synthesis routine: aggregating local ML models
" src="../images/media/image13.jpg" />{width="6.268055555555556in"
height="8.41388888888889in"}</p>
<p>Figure 3.8 -- Model synthesis routine: aggregating local ML models</p>
<ul>
<li>Aggregating local models to generate the global model has been
    explained. Now, let us look into the agent-side FL cycle, including
    the retraining process of the local ML models.</li>
</ul>
<p>Local Retraining Cycle - The agent-perspective</p>
<ul>
<li>
<p>In the distributed agent, the following state transition happens and
    is repeated for the continuous operation of the FL cycle:</p>
</li>
<li>
<p>In the state of waiting_gm, the agent polls the aggregator to
    receive any updates related to the global model. Basically, a
    polling method is used to regularly query the updated global model.
    However, under some specific settings, an aggregator can push the
    updated global model to all agents.</p>
</li>
<li>
<p>gm_ready is the state after the global model is formed by the
    aggregator and downloaded by the agent. The model parameters are
    cached in the agent device. The agent replaces its local ML model
    with the downloaded global model. Before completely replacing the
    local model with the downloaded model, the agent can check whether
    the output of the global model is sufficiently performant for the
    local ML engine. If the performance is not what is expected, the
    user can keep using the old model locally until it receives the
    global model that has the desired performance.</p>
</li>
<li>
<p>Next, in the training state, the agent can locally train the model
    in order to maximize its performance. The trained model is saved in
    a local data storage where training examples are kept. The FL client
    libraries of the agent ascertain its readiness to manipulate the
    local model that can be protected with asynchronous function access.</p>
</li>
<li>
<p>After the local model is trained, the agent checks whether the new
    global model has been sent to the agent or not. If the global model
    has arrived, then the locally trained ML model is discarded and goes
    back to the gm_ready state.</p>
</li>
<li>
<p>After local training, the agent proceeds with the sending state to
    send the updated local model back to the aggregator, and then, the
    agent goes back to the waiting_gm state.</p>
</li>
<li>
<p><em>Figure 3.9</em> depicts the state transition of an agent to adapt and
    update the ML model:</p>
</li>
</ul>
<p><img alt="Figure 3.9 -- Agent-side state transition to adapt and update the ML
model " src="../images/media/image52.jpg" />{width="5.709722222222222in"
height="7.125in"}</p>
<p>Figure 3.9 -- Agent-side state transition to adapt and update the ML
model</p>
<ul>
<li>Next, we touch on a model interpretation based on deviation from the
    baseline outputs that are used for anomaly detection and preventing
    model degradation.</li>
</ul>
<p>Model interpretation based on deviation from baseline outputs</p>
<ul>
<li>
<p>We can also provide an interpretation framework by looking at the
    output of each local model. The following procedure can be
    considered to ensure the local model is always good to use and can
    be deployed in production:</p>
</li>
<li>
<p>Obtain the most recent ML output generated by an agent as well as a
    baseline output that can be a typical desired output prepared by
    users. The baseline output could include an average output based on
    the past windows or reference points defined by an operator, subject
    expert, or rule-based algorithm.</p>
</li>
<li>
<p>The deviation between the output of the local model and the baseline
    output is computed.</p>
</li>
<li>
<p>An anomaly or performance degradation can be detected by checking
    whether the deviation exceeds the operator-specified threshold. If
    an anomaly is detected, an alarm can be sent to an operator to
    indicate a fault or that the ML model is in an anomalous state.</p>
</li>
<li>
<p>Now that the process of the FL has been explained, let us look into
    the basics of model aggregation, which comprise the critical part of
    FL.</p>
</li>
</ul>
<p>Model Aggregation - The Basics</p>
<ul>
<li>
<p>Aggregation is a core concept within FL. In fact, the strategies
    employed to aggregate models are the key theoretical driver for the
    performance of FL systems.</p>
</li>
<li>
<p>The purpose of this section is to introduce the high-level concepts
    of aggregation within the context of an FL system -- the underlying
    theory and examples of advanced aggregation strategies will be
    discussed in greater depth later when we discuss <em>Model
    Aggregation</em>.</p>
</li>
</ul>
<p>What does aggregation of models mean?</p>
<ul>
<li>
<p>Let's revisit the aggregator-side cycle discussed in earlier, at the
    point in the process where the agents assigned to a certain
    aggregator have finished training locally and have transmitted these
    models back to this aggregator.</p>
</li>
<li>
<p>The goal of any aggregation strategy, or any way of aggregating
    these models together, is to produce new models that gradually
    increase in performance across all of the data collected by the
    constituent agents.</p>
</li>
<li>
<p>An important point to remember is that FL is, by definition, a
    restricted version of the distributed learning setting, in which the
    data collected locally by each agent cannot be directly accessed by
    other agents.</p>
</li>
<li>
<p>If this restriction were not in place, a model could be made to
    perform well trivially on all of the data by collecting the data
    from each agent and training on the joint dataset; thus, it makes
    sense to treat this <em>centrally-trained</em> model as the target model
    for an FL approach.</p>
</li>
<li>
<p>At a high level, we can consider this unrestricted distributed
    learning scenario as aggregation before model training (where in
    this case, aggregation refers to combining the data from each
    agent).</p>
</li>
<li>
<p>Because FL does not allow data to be accessed by other agents, we
    consider the scenario as aggregation after model training instead;
    in this context, aggregation refers to the combination of the
    intelligence captured by each of the trained models from their
    differing local datasets.</p>
</li>
<li>
<p>To summarize, the goal of an aggregation strategy is to combine
    models in a way that eventually leads to a generalized model whose
    performance approaches that of the respective centrally trained
    model.</p>
</li>
</ul>
<p>FedAvg -- Federated averaging</p>
<ul>
<li>To make some of these ideas more concrete, let's take an initial
    look into one of the most well-known and straightforward aggregation
    strategies, known as <strong>Federated Averaging</strong> (<strong>FedAvg</strong>). The
    FedAvg algorithm is performed as follows:
    let <img alt="" src="../images/media/image23.png" />{width="1.2670089676290464in"
    height="0.2487379702537183in"} be the parameters of the models
    from <img alt="" src="../images/media/image35.png" />{width="0.20833333333333334in"
    height="0.20833333333333334in"} agents, each with a local dataset
    size
    of <img alt="" src="../images/media/image6.png" />{width="1.1828608923884514in"
    height="0.2213538932633421in"}.
    Also, <img alt="" src="../images/media/image12.png" />{width="0.20833333333333334in"
    height="0.20833333333333334in"} is the total dataset size defined
    as <img alt="" src="../images/media/image9.png" />{width="2.617024278215223in"
    height="0.29885826771653545in"}. Then, FedAvg returns the following
    ML model as the aggregated model:</li>
</ul>
<p><img alt="" src="../images/media/image1.jpg" />{width="4.697647637795275in"
height="0.54582239720035in"}</p>
<ul>
<li>
<p>Essentially, we perform FedAvg over a set of models by taking the
    weighted average of the models, with weights proportional to the
    size of the dataset used to train the model.</p>
</li>
<li>
<p>As a result, the types of models to which FedAvg can be applied are
    models that can be represented as some set of parameter values.</p>
</li>
<li>
<p>Deep neural networks are currently the most notable of these kinds
    of models -- most of the results analyzing the performance of FedAvg
    work with deep learning models.</p>
</li>
<li>
<p>It is rather surprising that this relatively simple approach can
    lead to generalization in the resulting model.</p>
</li>
<li>
<p>We can visually examine what FedAvg looks like within a toy
    two-dimensional parameter space to observe the benefits of the
    aggregation strategy:</p>
</li>
</ul>
<p><img alt="Figure 3.10 -- Two-dimensional parameter space with local models from
two agents (the circle and square) and a target model (the black x)
" src="../images/media/image5.jpg" />{width="6.268055555555556in"
height="4.636111111111111in"}</p>
<p>Figure 3.10 -- Two-dimensional parameter space with local models from
two agents (the circle and square) and a target model (the black x)</p>
<ul>
<li>
<p>Let's consider a case where we have two newly initialized models
    (the circle and square points) belonging to separate agents.</p>
</li>
<li>
<p>The space in the preceding figure represents the parameter space of
    the models, where each toy model is defined by two parameters.</p>
</li>
<li>
<p>As the models are trained, these points will move in the parameter
    space -- the goal is to approach a local optimum in the parameter
    space, generally corresponding to the aforementioned centrally
    trained model:</p>
</li>
</ul>
<p><img alt="Figure 3.11 -- Change in local model parameters without aggregation
" src="../images/media/image57.jpg" />{width="6.268055555555556in"
height="4.461111111111111in"}</p>
<p>Figure 3.11 -- Change in local model parameters without aggregation</p>
<ul>
<li>
<p>Each model converges to separate dataset-specific optima (two x
    points from the circle and square) that do not generalize.</p>
</li>
<li>
<p>Because each agent only has access to a subset of the data, the
    local optima reached by training each model locally will differ from
    the true local optima; this difference depends on how similar the
    underlying data distributions are for each agent.</p>
</li>
<li>
<p>If the models are only trained locally, the resulting models will
    likely not generalize over all of the data:</p>
</li>
</ul>
<p><img alt="Figure 3.12 -- Adding aggregation moves the local model parameters to
the average for both models at each step, leading to convergence at the
target model " src="../images/media/image4.jpg" />{width="6.268055555555556in"
height="4.631944444444445in"}</p>
<p>Figure 3.12 -- Adding aggregation moves the local model parameters to
the average for both models at each step, leading to convergence at the
target model</p>
<ul>
<li>
<p>Applying FedAvg at each movement step allows us to create an
    aggregate model that eventually comes close to the true local optima
    in the parameter space.</p>
</li>
<li>
<p>This example displays the basic capability of FedAvg to produce
    generalized models.</p>
</li>
<li>
<p>However, working with real models (such as highly parameterized deep
    learning models) introduces additional complexity that is handled by
    FedAvg but not by simpler approaches.</p>
</li>
<li>
<p>For example, we might wonder why we don't simply fully train each
    local model and only average at the end; while this approach would
    work in this toy case, it has been observed that only averaging once
    with real models leads to poor performance across all of the data.</p>
</li>
<li>
<p>The FedAvg process allows for a more robust way to reach the
    generalized model within high-dimension parameter spaces.</p>
</li>
<li>
<p>This section only aims to give an overview of aggregation in
    FL; the <em>Model Aggregation</em> section, contains more detailed
    explanations and examples for aggregation in different scenarios.</p>
</li>
<li>
<p>We now understand the entire process of how the FL system works with
    basic model aggregation. In some applications, the FL system may
    have to support a huge number of agents to realize its scalability.</p>
</li>
<li>
<p>The following section will give you some idea about how to scale
    more smoothly, especially with a decentralized horizontal design.</p>
</li>
</ul>
<p>Horizontal Design for Enhanced Scalability</p>
<ul>
<li>
<p>In this section, we will look into how to further scalability when
    we need to support a large number of devices and users.</p>
</li>
<li>
<p>There are practical cases where control, ease of maintenance and
    deployment, and low communication overhead are provided by
    centralized FL. If the number of agents is not large, it makes more
    sense to stick to centralized FL than decentralized FL.</p>
</li>
<li>
<p>However, when the number of participating agents becomes quite
    large, it may be worth looking into horizontal scaling with a
    decentralized FL architecture.</p>
</li>
<li>
<p>The latest developments of auto-scaling frameworks these days, such
    as the <strong>Kubernetes</strong> framework (https://kubernetes.io/, can be a
    nice integration with the topic that is discussed in this section,
    although actual integration and implementation with Kubernetes is
    beyond the scope of this material.</p>
</li>
</ul>
<p>Horizontal design with semi-global model</p>
<ul>
<li>
<p>There will be some use cases where many aggregators are needed to
    cluster groups of agents and create a global model on top of those
    many aggregators.</p>
</li>
<li>
<p>Google uses a centralized approach for this, as in the
    paper <em>Towards Federated Learning at Scale</em>, while setting up a
    centralized node for managing multiple aggregators may have some
    resilience issues.</p>
</li>
<li>
<p>The idea is simple: periodically aggregate all the cluster models at
    some central master node.</p>
</li>
<li>
<p>On the other hand, we can realize the decentralized way of
    aggregating cluster models created by multiple aggregators. The
    architecture for that is based on two crucial ideas:</p>
</li>
</ul>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>&lt;!-- --&gt;
</code></pre></div>
-   Model aggregation conducted among individual cluster aggregators
    without master nodes</p>
<ul>
<li>Semi-global model synthesis to aggregate cluster models generated by
    other aggregators</li>
</ul>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>&lt;!-- --&gt;
</code></pre></div>
-   To create semi-global models, decentralized cluster aggregators
    exchange their aggregated cluster models with each other and
    approximate optimal global models.</p>
<ul>
<li>
<p>The cluster aggregators can also use a database to periodically
    collect other cluster models to generate the semi-global models.</p>
</li>
<li>
<p>This framework allows for the absorption of training results from
    diverse sets of users dispersed across many aggregators by
    synthesizing the most updated global models without a master node
    concept.</p>
</li>
<li>
<p>Based on this decentralized architecture, the robustness of the
    entire FL system can be enhanced, as the semi-global model can be
    independently computed at each cluster aggregator.</p>
</li>
<li>
<p>The FL system can be scaled further, as each cluster aggregator is
    responsible for creating its own semi-global model by itself -- not
    via the master node of those aggregators -- and therefore,
    decentralized semi-global model formation comes with resiliency and
    mobility.</p>
</li>
<li>
<p>We can even decouple the database that stores the uploaded local
    models, cluster global models, and semi-global models.</p>
</li>
<li>
<p>By introducing a distributed database into the FL system, the entire
    system could be made more scalable, resilient, and secure together
    with some failover mechanism.</p>
</li>
<li>
<p>For example, each cluster aggregator stores the cluster model in a
    distributed database.</p>
</li>
<li>
<p>The cluster aggregators can retrieve cluster models of other
    aggregators by pulling the models periodically from the databases.
    At each cluster aggregator, a semi-global ML model is generated by
    synthesizing the pulled models.</p>
</li>
</ul>
<p><em>Figure 3.13</em> illustrates the overall architecture of the decentralized
horizontal design of a multi-aggregator FL system:</p>
<p><img alt="Figure 3.13 -- Architecture of a decentralized FL system with multiple
aggregators (horizontal design)
" src="../images/media/image20.jpg" />{width="6.268055555555556in"
height="2.0625in"}</p>
<p>Figure 3.13 -- Architecture of a decentralized FL system with multiple
aggregators (horizontal design)</p>
<ul>
<li>Now that we have discussed how to enhance the FL system with a
    horizontal design using the semi-global model concept, next, we will
    look at distributed database frameworks to further ensure
    scalability and resiliency.</li>
</ul>
<p>Distributed database</p>
<ul>
<li>
<p>Furthermore, the accountability of the model updates can be provided
    by storing historical model data in a data-driven distributed
    database.</p>
</li>
<li>
<p>The <strong>InterPlanetary File System</strong> (<strong>IPFS</strong>) and Blockchain
    are well-known distributed databases that ensure the accountability
    of global model updates.</p>
</li>
<li>
<p>After a cluster aggregator generates a semi-global model based on
    other cluster models, the semi-global model is stored in a
    distributed database.</p>
</li>
<li>
<p>The distributed database manages the information of those models
    with a unique identifier.</p>
</li>
<li>
<p>To maintain all the models consistently, including local, cluster,
    and semi-global models, each ML model is assigned a globally unique
    identifier, such as a hash value, which could be realized using the
    concept of a <strong>Chord Distributed Hash Table</strong> (<strong>Chord DHT</strong>).</p>
</li>
<li>
<p>The Chord DHT is a scalable peer-to-peer lookup protocol for
    internet applications.</p>
</li>
<li>
<p>The cluster aggregator can store metadata on the cluster models,
    such as timestamps and hash identifiers.</p>
</li>
<li>
<p>This gives us further accountability for model synthesis by ensuring
    the cluster models haven\'t been altered.</p>
</li>
<li>
<p>It is also possible to identify a set of aggregators that are
    sending harmful cluster models to destroy the semi-global models
    once the malicious models are detectable.</p>
</li>
<li>
<p>These models can be filtered by analyzing the patterns of the
    weights of the cluster model or deviation from the other cluster
    models when the difference is too big to rely on.</p>
</li>
<li>
<p>The nature of the distributed database is to store all the volatile
    state information of the distributed FL system.</p>
</li>
<li>
<p>The FL system can restore from the distributed database in the case
    of failure.</p>
</li>
<li>
<p>The cluster aggregators also exchange their cluster models based on
    a certain interval defined by the system operator.</p>
</li>
<li>
<p>Therefore, the mapping table between cluster models and aggregators
    needs to be logged in the database together with meta-information on
    the local, cluster, and semi-global models, such as the generation
    time of those models and the size of training samples.</p>
</li>
</ul>
<p>Asynchronous agent participation in a multiple-aggregator scenario</p>
<ul>
<li>
<p>Distributed agents can broadcast participation messages to
    connectable aggregators when they want to join their FL process.</p>
</li>
<li>
<p>The participation messages can contain the unique ID of the agent.
    One of the cluster aggregators then returns a cluster aggregator ID,
    potentially the value generated based on a common hash function, to
    which the agent should belong. </p>
</li>
<li>
<p><em>Figure 3.14</em> depicts how the agent is assigned to a certain cluster
    aggregator using a hash function:</p>
</li>
</ul>
<p><img alt="Figure 3.14 -- The sequence of an agent joining one of the cluster
aggregators in an FL system
" src="../images/media/image46.jpg" />{width="6.268055555555556in"
height="7.308333333333334in"}</p>
<p>Figure 3.14 -- The sequence of an agent joining one of the cluster
aggregators in an FL system</p>
<ul>
<li>In the following section, we will look into how the semi-global
    model is generated based on aggregating the multiple cluster global
    models.</li>
</ul>
<p>Semi-global model synthesis</p>
<ul>
<li>
<p>After the agent is assigned to a specific cluster aggregator, the
    agent starts to participate in the FL process.</p>
</li>
<li>
<p>It requests a base ML model if it is registered -- otherwise, it
    needs to upload the base model to start local training.</p>
</li>
<li>
<p>The procedure of uploading local models and generating cluster and
    semi-global models will continue until the agent or aggregator is
    disconnected from the system.</p>
</li>
<li>
<p>The sequence of the local and cluster model upload process,
    aggregation process, and semi-global model synthesis and pulling is
    illustrated in <em>Figure 3.15</em>:</p>
</li>
</ul>
<p><img alt="Figure 3.15 -- The sequence of the semi-global model synthesis
processes from uploading local models to pulling semi-global models
" src="../images/media/image10.jpg" />{width="6.268055555555556in"
height="3.134027777777778in"}</p>
<p>Figure 3.15 -- The sequence of the semi-global model synthesis processes
from uploading local models to pulling semi-global models</p>
<ul>
<li>
<p>Let's look at semi-global model synthesis using the flowchart
    between the agent, aggregator, and distributed database.</p>
</li>
<li>
<p>The aggregator receives a local model from an agent. When receiving
    the local model, the model filtering process will decide whether to
    accept the uploaded model or not.</p>
</li>
<li>
<p>This framework can be implemented using many different methods, such
    as a basic scheme of checking the difference between the weights of
    the global and local models. If the model is not valid, just discard
    the local model.</p>
</li>
<li>
<p>Then, a cluster model is created by aggregating all the accepted
    local models.</p>
</li>
<li>
<p>The aggregator stores the cluster model in a database, as well as
    simultaneously retrieving the cluster models generated by other
    cluster aggregators.</p>
</li>
<li>
<p>A semi-global model is then synthesized from those cluster models
    and will be used in the agents that are assigned to the cluster
    aggregator.</p>
</li>
<li>
<p><em>Figure 3.16</em> shows how the cluster aggregator proceeds with cluster
    and semi-global model synthesis using a distributed database:</p>
</li>
</ul>
<p><img alt="Figure 3.16 -- The procedure and flow of semi-global model synthesis
" src="../images/media/image43.jpg" />{width="6.268055555555556in"
height="8.567361111111111in"}</p>
<p>Figure 3.16 -- The procedure and flow of semi-global model synthesis</p>
<ul>
<li>
<p>An aggregator does not need to retrieve all the cluster models
    generated at each round to create a semi-global model. To synthesize
    a semi-global model, the global model can eventually converge based
    on the subset of models randomly selected by each aggregator.</p>
</li>
<li>
<p>Using this approach, the robustness and independence of aggregators
    will be enhanced by compromising on the conditions to create the
    global model at every update.</p>
</li>
<li>
<p>This framework can also resolve the bottlenecks in terms of
    computation and communication typical to centralized FL systems.</p>
</li>
</ul>
<p>Summary</p>
<ul>
<li>
<p>Here, we discussed the potential architecture, procedure flow, and
    message sequences within an FL system.</p>
</li>
<li>
<p>The typical FL system architecture consists of an aggregator,
    agents, and a database server.</p>
</li>
<li>
<p>These three components are constantly communicating with each other
    to exchange system information and ML models to achieve model
    aggregation.</p>
</li>
<li>
<p>The key to implementing a good FL system is decoupling the critical
    components and carefully designing the interfaces between them.</p>
</li>
<li>
<p>We focused on the aspect of the simplicity of its design so that
    further enhancement can be achieved by just adding additional
    components to the systems. Horizontal decentralized design can also
    help implement a scalable FL system.</p>
</li>
<li>
<p>In the following section, we will discuss the implementation details
    of achieving FL on the server side.</p>
</li>
<li>
<p>As some critical aspects of the functionalities have been introduced
    Here, you will be able to implement the basic system and smoothly
    run the simulation with some ML applications.</p>
</li>
</ul>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      &copy; 2024 <a href="https://spanda.io"  target="_blank" rel="noopener">Spanda.io</a>

    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://ranga-rangarajan.github.io/spanda-bootcamp/" target="_blank" rel="noopener" title="ranga-rangarajan.github.io" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "toc.integrate", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.caa56a14.min.js"></script>
      
    
  </body>
</html>